Was talking in lab to Nobie about how we would read-out the 90TB/sec of
data from recording voltage in every neuron in the human brain. We
weren't sure whether it would be best to go an optical route.

I have also been wondering about the actual analysis of the data and how
that would be dealt with in terms of time. It is well known in electron
microscopy that it is not the data collection where time is lost, but
the insane amount of time it takes to analyze the data. Knowing that
Google has to deal with analyzing massive amounts of data on a daily
basis---and due in part to methods like MapReduce---i asked Tom how
Google deals with this data deluge.

\href{http://tardigradesinspace.blogspot.com/}{Tardigrades} have been
found to \href{URL}{survive exposure to the vacuum and radiation of
space}. How their neurons still respond afterwards is quite
interesting\ldots{}
